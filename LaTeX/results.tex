\section{Results and conclusions}
\setlength{\abovecaptionskip}{0pt plus 0pt minus 2pt}

% 1 page
% Table with different experimental setups, file size, payload on diff setups (2048 byte on localhost, 1467 byte on WiFi and Net due to MTU), header size (32 seed + 8 block_ID bit), ACK size (32 packets needed + 8 block_ID bit). 

% time to decode NET_localhost (last column) - x axis N-K, different lines for each K

\begin{figure}
	\centering
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{0.5\textwidth}
	\setlength\fheight{200}
	\input{./figures/decoding_time.tex}
	\caption{Average time to decode a packet, notice that y axis is in logarithmic scale}
	\label{fig:decoding_time}
\end{figure}

% 3 pages
% localhost: goodput, efficiency with PER on x axis $K$ 1000 3500 5500, 3 plot per row, 2 rows
In our experiments to evaluate the performances of the system we have considered the transmission of a file of size 46.2 MB. Packets header consists in 32 bits of seed plus 8 bits of block ID (a block is a set of $K$ packets that are encoded into $N$ packets), for a total header size of 40 bits. The ACK consists in 32 bits to represent the number of packets the receiver still needs to get $N$ correct packets (therefore we allow for a value of $N$ up to $2^{32}\simeq 4\cdot 10^9$, which is more than enough for our purposes) plus 8 bits of block ID, again for a total of 40 bits. The various experimental scenarios have been summarized in Table 1.

\begin{center}
\begin{tabular}{ccc}

\toprule
scenario& payload (byte) &minimum timeout\\
& & before RTX (ms) \\
\midrule
localhost aggressive&2048&1\\
localhost efficient&2048&100\\
WiFi&1467&100\\
Network&1467&100\\
\bottomrule
\end{tabular}
\captionof{table}{Experimental setups}
\end{center}
The payload size of WiFi and network is dictated by the MTU size. \\
We remark that with these setting we are able to transmit a file of size up to 2.25 PB in localhost and 1.61 PB over WiFi or network if we have no redundancy.\\
The WiFi experiment was carried out using two different setups. In the \textit{high SNR} scenario sender and router, router and receiver are at a distance $d= 3$ m, with one brick wall between sender and router. The \textit{low SNR} scenario deployed sender and router in the same positions, but the receiver was moved 2 walls and 15 m away from the router. The WiFi router was a 802.11a/b/g device. 
The transmission over the network has been carried out from Padova to Lausanne. The sender was connected via WiFi to a FTTC connection with 10 Mbits in uplink, while the receiver was connected via Ethernet on a symmetric connection of 100 Mbits (therefore the bottleneck is 10 Mbits). For localhost and network experiments, the receiver was executed on a workstation with a 3.4 GHz i7 processor and 8 GB of RAM, while in both WiFi setups the laptop on which the receiver run had a 2.2 GHz i7 processor with 8 GB of RAM.

In all these regimes we consider a redundancy for which the probability of decoding failures (i.e. the receiver correctly receives $N$ packets, but they are not sufficient to decode the $K$ informative packets) is very low (typically $<10^{-3}$), and therefore negligible. \\
The first very important trade-off is between decoding time and transmission time as a function of the redundancy, which translates in most of the cases in a trade-off between goodput and efficiency. In fact, for a fixed $K$ and PER, adding redundancy decreases the time to decode, but it also increases the time to transmit the file (because there are more packets to transmit). In general we can write that $delay=transmission\_time+decoding\_time$ where \emph{transmission\_time} includes all time spent in propagation, waiting, retransmitting, etc. over the channel, and \emph{decoding\_time} is the time that it takes to the decoder to decoded a block of $N$ packets once they have all been correctly received. We can sum up these considerations in Table 2, where we show the dependencies of \emph{transmission\_time} and \emph{decoding\_time} on one parameter by keeping all others fixed.
\begin{center}
\begin{tabular}{c|c|c|c|c}

\toprule
&$K$&$N-K$&$\frac{N-K}{K}$&PER\\
\midrule
transmission\_time&$\sim$ indepentent& & $\nearrow$&$\nearrow$\\ \hline
decoding\_time&$\nearrow$&$\searrow$&&independent\\ 
\bottomrule
\end{tabular}
\captionof{table}{Monotonicities}
\end{center}


This trade-off is very well shown in Figures \ref{fig:goodput_aggr} and \ref{fig:efficiency_aggr}, which show the performance obtained in localhost with an aggressive ARQ (i.e. low timeout before retransmission). First of all we remark that the goodput decreases approximatively linearly with the packet error probability. Moreover, for $K$ small, adding redundancy decreases the goodput. In fact for $K$ small and redundancy starting at $N-K=1000$ (i.e. 100\%), transmission time prevails over decoding time, which, at these levels of redundancy, decreases slowly as a function of N. Therefore, since the transmission time increases with redundancy (we can assume that transmission time increases approximatively linearly in N), even though the decoding time decreases, the overall delay increases. Hence, the goodput decreases by adding redundancy.
On the other hand, if we increase K, we reduce the relative redundancy, and therefore the time to decode the file has more impact than the time to transmit it. As a consequence, it is better to choose high redundancy in order to decode faster, rather than reduce $N$ to transmit faster.\\
We also observe that goodput decreases with K. In fact in general in localhost, since transmission time is small, for a fixed absolute redundancy, increasing $K$ allows to marginally improve the time to transmit (lesser packets to transmit because the relative redundancy is lower), while it significantly increases the time to decode (because relative redundancy decreases). \\
However the efficiency, i.e. the ratio between informative and sent packets, always decreases with redundancy (since we are not taking into account the time to transmit the packets).\\
We also remark that the difference in goodput for a given $K$ and two values of $N$ decreases as PER increases. In fact we can write, for $N>N'$ and $PER>PER'$
\begin{equation}
\begin{split}
[delay(N,PER')-delay(N',PER')]-[delay(N,PER)-delay(N',PER)]=\\
=[tx\_time(N,PER')-tx\_time(N,PER)]-[tx\_time(N',PER')-tx\_time(N',PER)]
\end{split}
\end{equation}
because the decoding time does not depend on PER. If we assume that the transmission time is a linear function of the number of retransmissions, and that the number of packets left to transmit is a geometric sequence in the number of retransmission $r$, we can write $N\cdot PER^r=1 \Rightarrow r=-\frac{\ln(N)}{\ln(PER)}$, and therefore
\begin{equation}
\begin{split}
[delay(N,PER')-delay(N',PER')]-[delay(N,PER)-delay(N',PER)]=\\ 
=K\frac{\ln(N)}{\ln PER \ln PER'}\ln{\frac{PER'}{PER}}-K\frac{\ln(N')}{\ln PER \ln PER'}\ln{\frac{PER'}{PER}}=\frac{K}{\ln PER \ln PER'}\ln{\frac{PER'}{PER}}\ln{\frac{N}{N'}}<0
\end{split}
\end{equation}
since $N>N'$ and $1>PER>PER'>0$. Therefore the gap in delay increases as PER increases, and since the goodput depends on the inverse of the delay, the gap in goodput decreases as PER increases.
\begin{figure}[!hp]
\centering
\begin{subfigure}{0.24\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_1000.tex}
	\caption{$K=1000$}
	\label{fig:lh_good_1000}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_3500.tex}
	\caption{$K=3500$}
	\label{fig:lh_good_3500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_5500.tex}
	\caption{$K=5500$}
	\label{fig:lh_good_5500}
\end{subfigure}
\caption{Goodput for $K \in \{1000, 3500, 5500\}$ in localhost, aggressive setup}
\label{fig:goodput_aggr}
\end{figure}

\begin{figure}[!hp]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_1000.tex}
	\caption{$K=1000$}
	\label{fig:lh_eff_1000}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_3500.tex}
	\caption{$K=3500$}
	\label{fig:lh_eff_3500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_5500.tex}
	\caption{$K=5500$}
	\label{fig:lh_eff_5500}
\end{subfigure}
\caption{Efficiency for $K \in \{1000, 3500, 5500\}$ in localhost, aggressive setup}
\label{fig:efficiency_aggr}
\end{figure}

% TODO NET_localhost: goodput, efficiency with PER on x axis $K$ 1000 3500 5500, 3 plot per row, 2 rows
% Relation between different parameters (K, N) and goodput/efficiency. Tradeoff redundancy goodput time to decode.
% Compare the two setup and show the tradeoff between goodput and efficiency, according to the different timeout settings.
% Something on useless packets (i.e. packets that arrive after the completion of a decoding attempt, that may be sent after 
% the reception of previous ACKs), notice that they tend to 0.

\begin{figure}[!hp]
\centering
\begin{subfigure}{0.24\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_1000_100ms.tex}
	\caption{$K=1000$}
	\label{fig:lh_good_1000_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_3500_100ms.tex}
	\caption{$K=3500$}
	\label{fig:lh_good_3500_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_5500_100ms.tex}
	\caption{$K=5500$}
	\label{fig:lh_good_5500_eff}
\end{subfigure}
\caption{Goodput for $K \in \{1000, 3500, 5500\}$ in localhost, efficiency oriented setup}
\label{fig:goodput_nonaggr}
\end{figure}

\begin{figure}[!hp]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_1000_100ms.tex}
	\caption{$K=1000$}
	\label{fig:lh_eff_1000_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_3500_100ms.tex}
	\caption{$K=3500$}
	\label{fig:lh_eff_3500_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_efficiency_5500_100ms.tex}
	\caption{$K=5500$}
	\label{fig:lh_eff_5500_eff}
\end{subfigure}
\caption{Efficiency for $K \in \{1000, 3500, 5500\}$ in localhost, efficiency oriented setup}
\label{fig:eff_nonaggr}
\end{figure}


% 3 pages
% wifi: goodput and efficiency, with x axis with $N$ - K, also throughput, show that for N-K small the decoding time is more significant than rx time. 
Again, in Fig. \ref{fig:wifi} we see the trade-off between goodput and efficiency. Efficiency is always monotonic with respect to redundancy, whereas the behavior of the goodput is more complicated, and depends on which between the transmission time and the decoding time prevails. In particular we see that gooput increases dramatically for high $K$ when we pass from a redundancy of 1000 to a redundancy of 1500. This, again, is due to the fact that too little redundancy (in ratio with respect to K) yields longer decoding times, which can dominate over the transmission time, and therefore degrades the performances. This explains the peak at $N-K=1500$ for high K: for lower redundancy performance is dictated by decoding time (which increases as redundancy decreases), whereas for higher redundancy performance depends mainly on transmission time (which increases as redundancy increases, since we have more packets to transmit). Therefore goodput depends both on an increasing and decreasing function with respect to redundancy, which explains the non-monotonicity.  We also remark that clearly throughput increases with redundancy, since we reduce the time to decode, whereas the time to transmit the single packets doesn't change very much (if the transmission rate of the packet is high enough, which is the case for WiFi g which is approximatively 50 Mbit/s). This is confirmed by the fact that the increase in throughput is greater for low K, because we are adding in percentage more redundancy, which greatly increase the decoding time. 
\begin{figure}[!hp]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_eff.tex}
	\caption{Efficiency}
	\label{fig:wifi_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_goodput.tex}
	\caption{Goodput}
	\label{fig:wifi_good}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_throughput.tex}
	\caption{Throughput}
	\label{fig:wifi_thr}
\end{subfigure}
\caption{Metrics for WiFi simulation. }
\label{fig:wifi}
\end{figure}
% $K$ = 4500, possibly others, show the difference between a nice setting and a low snr setting
In Figures \ref{fig:wifi_lsnr_3500} and \ref{fig:wifi_lsnr_4500} we show the experimental results obtained using WiFi in a \textit{high SNR} scenario and \textit{low SNR} scenario for two different values of K. Even though experimental measurements show quite a large variance (as can be noted by observing the interval of confidence), it appears quite clearly that, as expected, in the high SNR scenario we obtain better performances with respect to the low SNR case. However measurement uncertainties do not allow to draw further and more precise conclusions (even though we can assume that the qualitative behavior does not differ very much from the other cases, and the same considerations apply).
\begin{figure}[!hp]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_eff_lsnr_3500.tex}
	\caption{Efficiency}
	\label{fig:wifi_eff_lsnr_3500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_goodput_lsnr_3500.tex}
	\caption{Goodput}
	\label{fig:wifi_good_lsnr_3500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_throughput_lsnr_3500.tex}
	\caption{Throughput}
	\label{fig:wifi_thr_lsnr_3500}
\end{subfigure}
\caption{Comparison between setup with \textit{high SNR} and setup with \textit{low SNR}, for $K=3500$}
\label{fig:wifi_lsnr_3500}
\end{figure}
\begin{figure}[!h]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_eff_lsnr_4500.tex}
	\caption{Efficiency}
	\label{fig:wifi_eff_lsnr_4500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_goodput_lsnr_4500.tex}
	\caption{Goodput}
	\label{fig:wifi_good_lsnr_4500}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/wifi_throughput_lsnr_4500.tex}
	\caption{Throughput}
	\label{fig:wifi_thr_lsnr_4500}
\end{subfigure}
\caption{Comparison between setup with \textit{high SNR} and setup with \textit{low SNR}, for $K=4500$}
\label{fig:wifi_lsnr_4500}
\end{figure}
% few words on MTU


Fig. \ref{fig:net} shows the results of packet transmission between Padova and Lausanne. Also here we see the same qualitative behavior of the other cases. In particular we remark the crossing of the goodput curves for K=3500 and K=4500 due to the fact that when redundancy is too small, the time to decode a block increases significantly and impacts on the performances (even though less with respect to the WiFi scenario since in this scenario the transmission time is higher, since we have to transmit a packet through a network of approximatively 12 hops).
% net: goodput and efficiency, with x axis with $N$ - K, also throughput, show that for N-K small the decoding time is more significant than rx time. 
\begin{figure}[!hp]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/net_eff.tex}
	\caption{Efficiency}
	\label{fig:net_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/net_goodput.tex}
	\caption{Goodput}
	\label{fig:net_good}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/net_throughput.tex}
	\caption{Throughput}
	\label{fig:net_thr}
\end{subfigure}
\caption{Metrics for Net simulation}
\label{fig:net}
\end{figure}

% comparison between RF and LT in localhost
% TODO decoding time comparison
Fig. \ref{fig:RFLT} shows a choice of $N$ and $K$ which yield approximately the same efficiency for Random Fountain and LT, but allow for a much bigger goodput with LT, proving therefore the usefulness of LT. In fact, using RF, we are constrained to low values of $N$ and $K$ because of the complexity of the Gaussian elimination. Low values of $K$ oblige to a greater relative redundancy to have low possibility of failing the decode, and moreover result in more blocks (of $K$ packets), which imply a bigger delay. Hence, the goodput decreases.
\begin{figure}[!h]
\centering
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_eff_LT3500_RF.tex}
	\caption{Efficiency}
	\label{fig:RF_eff}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	\input{./figures/localhost_goodput_LT3500_RF.tex}
	\caption{Goodput}
	\label{fig:RF_good}
\end{subfigure}\hspace{2em}%
\begin{subfigure}{0.23\textwidth}
	\captionsetup{justification=centering,font=scriptsize}
	\centering
	\setlength\fwidth{\textwidth}
	\setlength\fheight{140}
	%\input{./figures/net_throughput.tex}
	\caption{Decoding time per packet}
	\label{fig:RFLT_dectime}
\end{subfigure}
\caption{Comparison between LT, $K=3500$ \& $N=4500$, and RF, $K=12$ \& $N=17$}
\label{fig:RFLT}
\end{figure}